{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "from tqdm import tqdm,trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从fmri数据和keys数据中取交集，找到共同keys部分数据\n",
    "#对于每个个体进行如下操作：\n",
    "    #首先从原始keys数据中读取边信息，再将frmi数据中为空的index去除，计算皮尔逊系数矩阵\n",
    "    #计算功能相关性系数矩阵和结构的相连矩阵,分别保存成两个matlab矩阵\n",
    "    #计算低秩稀疏矩阵，，matlab\n",
    "    #利用低秩稀疏矩阵抽象为大脑网络\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_path=\"../matfile/res_fmri_data/111009_rfMRI_REST1_LR_Atlas.dtseries.mat\"\n",
    "data=sio.loadmat(fmri_path)[\"fmri_mat\"]\n",
    "# print(data.keys(\"fmri_mat\"))\n",
    "# print(data[\"fmri_mat\"])\n",
    "#统计有多少nan值\n",
    "# print(np.isnan(data[\"fmri_mat\"]).sum()/1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#求出所有个体\n",
    "structual_path=\"../matfile/distance_4/\"\n",
    "function_path=\"../matfile/res_fmri_data/\"\n",
    "\n",
    "structual_keys=os.listdir(structual_path)\n",
    "structual_keys=[i[:6]for i in structual_keys if i.endswith(\"keys.mat\")] \n",
    "function_keys=os.listdir(function_path)\n",
    "function_keys=[i[:6]for i in function_keys ]\n",
    "keys_all=set(structual_keys).intersection(set(function_keys))\n",
    "keys_all=list(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6081 6081\n"
     ]
    }
   ],
   "source": [
    "key_test=keys_all[0]\n",
    "INDEX_path=\"../matfile/surfaces/\"\n",
    "# INDEX=sio.loadmat(INDEX_path+key_test+\"_INDEX.mat\")[\"INDEX\"]\n",
    "keys_path=\"../matfile/distance_4/\"\n",
    "#拿到index标签数据\n",
    "index_data=sio.loadmat(INDEX_path+key_test+\"INDEX.mat\")[\"INDEX\"][0][0][0]\n",
    "indexs=list(index_data[1:])\n",
    "indexs\n",
    "index_to_oringin_dic={}\n",
    "oringin_to_index_dic={}\n",
    "for i in range(len(indexs)):\n",
    "    index_to_oringin_dic[i+1]=indexs[i]\n",
    "    oringin_to_index_dic[indexs[i]]=i+1\n",
    "#index 在连接矩阵中不一定拥有全部的值\n",
    "print(len(indexs),len(index_to_oringin_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6081, 1200)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmri_data=sio.loadmat(function_path+key_test+\"_rfMRI_REST1_LR_Atlas.dtseries.mat\")[\"fmri_mat\"]\n",
    "#取出的仅仅是取了index之后的那些数据\n",
    "fmri_data=fmri_data[indexs]\n",
    "fmri_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 22, 26, 30, 34, 38, 42, 45, 49, 53, 57, 60, 63, 66, 127, 129, 131, 133, 135, 137, 139, 142, 145, 147, 149, 151, 153, 156, 159, 304, 318, 321, 324, 328, 335, 338, 364, 401, 432, 436, 463, 471, 477, 491, 506, 530, 536, 574, 597, 600, 606, 612, 616, 630, 635, 671, 696, 702, 713, 725, 752, 765, 788, 793, 804, 840, 854, 864, 875, 908, 924, 931, 938, 951, 959, 966, 1013, 1024, 1032, 1046, 1074, 1078, 1135, 1152, 1156, 1175, 1180, 1217, 1273, 1310, 1334, 1357, 1413, 1416, 1485, 1819, 1823, 1826, 1829, 2520, 2603, 2674, 2682, 2748, 2785, 2854, 2859, 2919, 2999, 3007, 3054, 3057, 3085, 3129, 3132, 3144, 3147, 3155, 3207, 3214, 3226, 3239, 3244, 3249, 3261, 3266, 3284, 3290, 3298, 3304, 3311, 3323, 3350, 3354, 19832, 19834, 19840, 19844, 19848, 19861, 19865, 19869, 19874, 19880, 19886, 26500, 26599, 26699, 26786, 26790, 26882, 26928, 26959, 26964, 27009, 27022, 27039, 27053, 27059, 27082, 27087, 27129, 27138, 27142, 27155, 27160, 27170, 27183, 27243, 27247, 27262, 27269, 27273, 27291, 27317, 27331, 27340, 27344, 27368, 27387, 27395, 27413, 27420, 27429, 27432, 27451, 27481, 27497, 27500, 27511, 27518, 27527, 27530, 27544, 27557, 27570, 27595, 27597, 27600, 27607, 27611, 27624, 27632, 27635, 27658, 27665, 27668, 27671, 27674, 27678, 27701, 27720, 27726, 27728, 27765, 27768, 27783, 27797, 28032, 28134, 28281, 28465, 32499, 32514, 32518, 32522, 32619, 32624, 32634, 32637, 32639, 32641, 32643, 32645, 32648, 32651, 32760, 32810, 32825, 32846, 32912, 32933, 32997, 33017, 33041, 33059, 33063, 33081, 33160, 33185, 33200, 33247, 33253, 33276, 33378, 33383, 33401, 33405, 33411, 33466, 33488, 33494, 33499, 33521, 33540, 33554, 33566, 33571, 33611, 33633, 33640, 33678, 33735, 33740, 33789, 33803, 33823, 33855, 33885, 33907, 33952, 33957, 33998, 34312, 35088, 35167, 35206, 35244, 35347, 35411, 35443, 35501, 35579, 35581, 35600, 35669, 35742, 52332, 52357, 52361, 52366, 52371, 53907, 53923, 59040, 59094, 59141, 59185, 59234, 59284, 59332, 59366, 59372, 59454, 59457, 59460, 59463, 59511, 59541, 59570, 59574, 59577, 59584, 59592, 59633, 59656, 59662, 59673, 59689, 59696, 59703, 59720, 59750, 59762, 59791, 59799, 59805, 59840, 59849, 59858, 59866, 59875, 59892, 59912, 59934, 59944, 59948, 59953, 59991, 59994, 59998, 60010, 60026, 60036, 60045, 60062, 60065, 60070, 60095, 60104, 60110, 60127, 60132, 60139, 60142, 60153, 60182, 60184, 60195, 60221, 60232, 60268, 60274, 60284, 60302, 60574, 60627, 60772, 60821]\n"
     ]
    }
   ],
   "source": [
    "#为空的数据在这部分需要重新去掉\n",
    "remove_index=list(set(np.where(np.isnan(fmri_data))[0]))\n",
    "remove_index=[i for i in remove_index]\n",
    "remove_index.sort()\n",
    "fmri_dic={}\n",
    "for i in range(len(indexs)):\n",
    "    fmri_dic[i]=indexs[i]\n",
    "\n",
    "# print(remove_index)\n",
    "remove_index_anti=[fmri_dic[i] for i in remove_index]\n",
    "print(remove_index_anti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5719\n"
     ]
    }
   ],
   "source": [
    "edge_list=load_edge(structual_path+key_test+\"keys.mat\")\n",
    "\n",
    "edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "\n",
    "# for item in tqdm(edge_list):\n",
    "#     if item[0]  in remove_index_anti or item[1]  in remove_index_anti:\n",
    "#         pass\n",
    "#     else:\n",
    "#          edge_new.append((int(item[0]),int(item[1])))\n",
    "\n",
    "# for it in edge_list:\n",
    "#     node_list.add(int(it[0]))\n",
    "#     node_list.add(int(it[1]))\n",
    "# node_list=list(node_list)\n",
    "# # node_list\n",
    "edge_list_new,node1,node2=reindex(edge_list)\n",
    "print(len(node1))\n",
    "structual_index=[index_to_oringin_dic[i] for i in node1]\n",
    "# structual_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 23, 28, 32, 36, 39, 43, 47, 50, 54, 100, 104, 107, 111, 118, 126, 128, 131, 133, 135, 137, 151, 154, 157, 164, 169, 172, 175, 280, 302, 308, 312, 315, 323, 327, 345, 390, 401, 423, 435, 455, 461, 469, 490, 514, 527, 534, 548, 580, 587, 604, 654, 660, 677, 694, 709, 715, 719, 734, 749, 786, 802, 809, 813, 832, 838, 848, 867, 883, 904, 917, 951, 959, 971, 977, 1024, 1050, 1105, 1114, 1766, 1769, 1772, 1779, 1782, 2124, 2284, 2367, 2414, 2421, 2496, 2521, 2532, 2675, 2683, 2700, 2749, 2822, 2827, 2866, 2875, 2888, 2910, 2930, 2950, 2955, 2962, 2971, 2993, 3016, 3030, 3034, 3064, 3070, 3086, 3091, 3099, 3105, 3124, 3139, 19193, 19213, 19237, 19248, 19261, 19265, 19299, 19304, 20213, 25061, 25155, 25188, 25191, 25214, 25231, 25255, 25277, 25281, 25283, 25285, 25302, 25307, 25310, 25313, 25342, 25348, 25362, 25368, 25387, 25394, 25397, 25407, 25417, 25423, 25445, 25450, 25453, 25470, 25473, 25477, 25481, 25499, 25503, 25507, 25525, 25528, 25531, 25533, 25552, 25556, 25559, 25577, 25580, 25864, 26059, 26425, 30414, 30504, 30507, 30509, 30667, 30669, 30685, 30688, 30696, 30703, 30727, 30789, 30791, 30804, 30813, 30838, 30841, 30850, 30858, 30878, 30881, 30904, 30928, 30956, 31015, 31024, 31027, 31032, 31036, 31045, 31056, 31064, 31067, 31073, 31076, 31094, 31107, 31138, 31142, 31155, 31170, 31175, 31184, 31187, 31229, 31231, 31257, 31261, 31269, 31274, 31335, 31973, 32518, 32575, 32591, 32613, 32619, 32647, 32649, 32657, 32662, 32668, 49582, 49613, 49638, 50549, 56276, 56287, 56307, 56356, 56373, 56381, 56395, 56401, 56423, 56430, 56445, 56457, 56464, 56466, 56472, 56477, 56490, 56519, 56521, 56536, 56543, 56550, 56569, 56582, 56584, 56612, 56624, 56627, 56638, 56641, 56655, 56673, 56676, 56678, 56681, 56686, 56691, 56694, 56703, 56712, 56720, 56759, 56770, 56777, 56779, 56781, 56785, 56798, 56801, 56805, 56831, 56843, 56846, 56863, 56866, 56882, 56884, 56894, 57364, 57454, 57586]\n"
     ]
    }
   ],
   "source": [
    "fmri_data=sio.loadmat(function_path+key_test+\"_rfMRI_REST1_LR_Atlas.dtseries.mat\")[\"fmri_mat\"]\n",
    "#取出的仅仅是取了index之后的那些数据\n",
    "fmri_data=fmri_data[structual_index]\n",
    "fmri_data.shape\n",
    "#为空的数据在这部分需要重新去掉\n",
    "remove_index=list(set(np.where(np.isnan(fmri_data))[0]))\n",
    "remove_index=[i+1 for i in remove_index]\n",
    "remove_index.sort()\n",
    "# print(remove_index)\n",
    "remove_index_anti=[index_to_oringin_dic[i] for i in remove_index]\n",
    "print(remove_index_anti)\n",
    "#去除这部分的空值index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structual_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\PROJECT\\CODE\\python_code\\funcional_cal.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/PROJECT/CODE/python_code/funcional_cal.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_index\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(structual_index)\u001b[39m-\u001b[39m\u001b[39mset\u001b[39m(remove_index_anti))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PROJECT/CODE/python_code/funcional_cal.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m all_index\u001b[39m.\u001b[39msort()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/PROJECT/CODE/python_code/funcional_cal.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m function_matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'structual_index' is not defined"
     ]
    }
   ],
   "source": [
    "all_index=list(set(structual_index)-set(remove_index_anti))\n",
    "all_index.sort()\n",
    "function_matrix=None\n",
    "print(all_index[:50])\n",
    "print(len( all_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "fmri_data_new=sio.loadmat(function_path+key_test+\"_rfMRI_REST1_LR_Atlas.dtseries.mat\")[\"fmri_mat\"]\n",
    "# fmri_data=fmri_data[all_index]\n",
    "functional_matrix=fmri_data_new[all_index]\n",
    "print(np.where(np.isnan(functional_matrix))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5308, 5308)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_matrix\n",
    "fun_corr=np.corrcoef(functional_matrix)\n",
    "fun_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5297, 5297)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structual_matrix=np.zeros((len(all_index),len(all_index)))\n",
    "\n",
    "edge_list=load_edge(structual_path+key_test+\"keys.mat\")\n",
    "edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "#从原始数据中获取 \n",
    "\n",
    "\n",
    "\n",
    "structual_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98730/98730 [00:20<00:00, 4815.60it/s] \n"
     ]
    }
   ],
   "source": [
    "for edge in tqdm(edge_list):\n",
    "    if index_to_oringin_dic[edge[0]] in all_index and index_to_oringin_dic[edge[1]] in all_index:\n",
    "        # print(\"ss\")\n",
    "        index_matrix_x=all_index.index(index_to_oringin_dic[edge[0]])\n",
    "        index_matrix_y=all_index.index(index_to_oringin_dic[edge[1]])\n",
    "        structual_matrix[index_matrix_x,index_matrix_y]=1\n",
    "        structual_matrix[index_matrix_y,index_matrix_x]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 27979167, 1.0: 79042}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.savetxt(\"structual_matrix.txt\",structual_matrix,fmt=\"%d\")\n",
    "\n",
    "unique,count=np.unique(structual_matrix,return_counts=True)\n",
    "data_count=dict(zip(unique,count))\n",
    "data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sio.savemat(\"structual_matrix.mat\",{\"structual_matrix\":structual_matrix})\n",
    "sio.savemat(\"functional_matrix.mat\",{\"functional_matrix\":fun_corr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 6.80103491e-04, ...,\n",
       "        1.51753477e-03, 0.00000000e+00, 7.89399757e-05],\n",
       "       [0.00000000e+00, 0.00000000e+00, 9.88624336e-04, ...,\n",
       "        3.19641116e-06, 4.24672166e-05, 2.04327236e-04],\n",
       "       [6.80103491e-04, 9.88624336e-04, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 9.62380988e-04],\n",
       "       ...,\n",
       "       [1.51753477e-03, 3.19641116e-06, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 2.99482491e-02, 4.44113893e-03],\n",
       "       [0.00000000e+00, 4.24672166e-05, 0.00000000e+00, ...,\n",
       "        2.99482491e-02, 0.00000000e+00, 4.81601328e-02],\n",
       "       [7.89399757e-05, 2.04327236e-04, 9.62380988e-04, ...,\n",
       "        4.44113893e-03, 4.81601328e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data=sio.loadmat(\"result.mat\")[\"A\"]\n",
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130030\n"
     ]
    }
   ],
   "source": [
    "index=np.where(result_data>0.01)\n",
    "print(len(index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终保存的节点数：5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "structual: 100%|██████████| 95446/95446 [00:20<00:00, 4739.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import *\n",
    "from tqdm import tqdm,trange\n",
    "\n",
    "structual_path=\"../matfile/distance_4/\"\n",
    "function_path=\"../matfile/res_fmri_data/\"\n",
    "\n",
    "structual_keys=os.listdir(structual_path)\n",
    "structual_keys=[i[:6]for i in structual_keys if i.endswith(\"keys.mat\")] \n",
    "function_keys=os.listdir(function_path)\n",
    "function_keys=[i[:6]for i in function_keys ]\n",
    "keys_all=set(structual_keys).intersection(set(function_keys))\n",
    "keys_all=list(keys_all)\n",
    "\n",
    "def save_all_index(index,name):\n",
    "    save_path=\"../matfile/functional_and_structual_matrix/\"\n",
    "    with open(save_path+name+\"all_inde.txt\",'w') as f:\n",
    "        for i in index:\n",
    "            f.write(str(i)+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "key_test=keys_all[0]\n",
    "INDEX_path=\"../matfile/surfaces/\"\n",
    "# INDEX=sio.loadmat(INDEX_path+key_test+\"_INDEX.mat\")[\"INDEX\"]\n",
    "keys_path=\"../matfile/distance_4/\"\n",
    "#拿到index标签数据\n",
    "index_data=sio.loadmat(INDEX_path+key_test+\"INDEX.mat\")[\"INDEX\"][0][0][0]\n",
    "indexs=list(index_data[1:])\n",
    "index_to_oringin_dic={}\n",
    "oringin_to_index_dic={}\n",
    "for i in range(len(indexs)):\n",
    "    index_to_oringin_dic[i+1]=indexs[i]\n",
    "    oringin_to_index_dic[indexs[i]]=i+1\n",
    "\n",
    "#去除structual index\n",
    "fmri_data=sio.loadmat(function_path+key_test+\"_rfMRI_REST1_LR_Atlas.dtseries.mat\")[\"fmri_mat\"]\n",
    "#取出的仅仅是取了index之后的那些数据\n",
    "fmri_data=fmri_data[indexs]\n",
    "fmri_data.shape\n",
    "\n",
    "#求需要去除的nan对应的index\n",
    "remove_index=list(set(np.where(np.isnan(fmri_data))[0]))\n",
    "remove_index=[i for i in remove_index]\n",
    "remove_index.sort()\n",
    "fmri_dic={}\n",
    "for i in range(len(indexs)):\n",
    "    fmri_dic[i]=indexs[i]\n",
    "\n",
    "# print(remove_index)\n",
    "remove_index_anti=[fmri_dic[i] for i in remove_index]\n",
    "# print(remove_index_anti)\n",
    "\n",
    "\n",
    "edge_list=load_edge(structual_path+key_test+\"keys.mat\")\n",
    "edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "edge_list_new,node1,node2=reindex(edge_list)\n",
    "structual_index=[index_to_oringin_dic[i] for i in node1]\n",
    "\n",
    "all_index=list(set(structual_index)-set(remove_index_anti))\n",
    "all_index.sort()\n",
    "print(\"最终保存的节点数：\"+str(len(all_index)))\n",
    "save_all_index(all_index,key_test)\n",
    "#读取fmri数据并求出corr\n",
    "fmri_data_new=sio.loadmat(function_path+key_test+\"_rfMRI_REST1_LR_Atlas.dtseries.mat\")[\"fmri_mat\"]\n",
    "# fmri_data=fmri_data[all_index]\n",
    "functional_matrix=fmri_data_new[all_index]\n",
    "functional_matrix\n",
    "fun_corr=np.corrcoef(functional_matrix)\n",
    "#计算structual数据\n",
    "structual_matrix=np.zeros((len(all_index),len(all_index)))\n",
    "edge_list=load_edge(structual_path+key_test+\"keys.mat\")\n",
    "edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "for edge in tqdm(edge_list,desc=\"structual\"):\n",
    "    if index_to_oringin_dic[edge[0]] in all_index and index_to_oringin_dic[edge[1]] in all_index:\n",
    "        # print(\"ss\")\n",
    "        index_matrix_x=all_index.index(index_to_oringin_dic[edge[0]])\n",
    "        index_matrix_y=all_index.index(index_to_oringin_dic[edge[1]])\n",
    "        structual_matrix[index_matrix_x,index_matrix_y]=1\n",
    "        structual_matrix[index_matrix_y,index_matrix_x]=1\n",
    "\n",
    "#保存数据\n",
    "save_path=\"../matfile/functional_and_structual_matrix/\"\n",
    "sio.savemat(f\"{save_path}{key_test}structual_matrix.mat\",{\"structual_matrix\":structual_matrix})\n",
    "sio.savemat(f\"{save_path}{key_test}functional_matrix.mat\",{\"functional_matrix\":fun_corr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "5413\n"
     ]
    }
   ],
   "source": [
    "print(np.where(np.isnan(functional_matrix)))\n",
    "\n",
    "print(len(functional_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_matrix(path):\n",
    "    data=sio.loadmat(path)[\"A\"]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189570\n"
     ]
    }
   ],
   "source": [
    "print(len(np.where(data>0.01)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_all=os.listdir(\"../matfile/result_low_matrix/\")\n",
    "keys_all=[i[:6]for i in keys_all if i.endswith(\"mat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_list_from_matrix(matrix):\n",
    "    edge_list=[]\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(i,len(matrix)):\n",
    "            if matrix[i][j]>0.01 :\n",
    "                edge_list.append((i,j))\n",
    "    return edge_list\n",
    "def save_edges_to_txt(edge_list,name):\n",
    "    save_path=\"../graph_file/result_low_matrix/\"\n",
    "    with open(save_path+name+\".txt\",'w') as f:\n",
    "        for i in edge_list:\n",
    "            f.write(str(i[0])+\" \"+str(i[1])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [04:53<00:00,  7.54s/it]\n"
     ]
    }
   ],
   "source": [
    "path=\"../matfile/result_low_matrix/\"\n",
    "\n",
    "for key in tqdm(keys_all):\n",
    "      \n",
    "    data=load_matrix(path+key+\".mat\")\n",
    "    data.shape\n",
    "    edges=get_edge_list_from_matrix(data)\n",
    "    edge_new,dic1,dic2=reindex(edges)\n",
    "    # save_txt_for_edges(edge_new,key+\"_new.txt\")\n",
    "\n",
    "    save_edges_to_txt(edge_new,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edge_from_txt(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        edge_list=[]\n",
    "        for line in f.readlines():\n",
    "            edge_list.append(line.strip().split(\" \"))\n",
    "    return edge_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir(\"../graph_file/result_low_matrix/\")\n",
    "for file in files:\n",
    "    edge_list=load_edge_from_txt(\"../graph_file/result_low_matrix/\"+file)\n",
    "    edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "    edge_new,dic1,dic2=reindex(edge_list)\n",
    "    save_txt_for_edges(edge_new,file[:-4]+\"_new.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_txt_for_edges(edge_list,\"115825.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_new,dic1,dic2=reindex(edge_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.read_edgelist(\"../graph_file/result_low_matrix/115825.txt\",nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取结果节点->由reindex计算index,还原原始index->读取index文件->\n",
    "# 读取surface文件，获取节点对应坐标-》存入到文件中\n",
    "def get_node_vtk_from_low_matrix(key):\n",
    "    result_path=\"../graph_file/result_low_matrix/\"\n",
    "    oringin_graph_path=\"../graph_file/low_matrix/\"\n",
    "    index_path=\"../matfile/functional_and_structual_matrix/\"\n",
    "    surface_path=\"../matfile/surfaces/\"\n",
    "\n",
    "\n",
    "    # surface_data=sio.loadmat(\"../matfile/surface_data.mat\")[\"surface_data\"]\n",
    "    edge_list=load_edge_from_txt(oringin_graph_path+key+\"_new.txt\")\n",
    "    edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "    _,_,dic2=reindex(edge_list)\n",
    "    result_nodes=[]\n",
    "    with open(result_path+key+\"_new.txt\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            result_nodes.append(dic2[int(line.strip())])\n",
    "    index_low_matrix=[]\n",
    "    with open(index_path+key+\"all_inde.txt\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            index_low_matrix.append(int(line.strip()))\n",
    "    index_dic={}\n",
    "    for i in range(len(index_low_matrix)):\n",
    "        \n",
    "        index_dic[i]=index_low_matrix[i]\n",
    "    vertex_data=sio.loadmat(surface_path+key+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "    result_vertice=[]\n",
    "    # print(result_nodes)\n",
    "    for i in result_nodes[:200]:\n",
    "        #此处-1是为了匹配matlab数据中的Index\n",
    "        # index_dic[i]\n",
    "        result_vertice.append(vertex_data[index_dic[i]-1])\n",
    "    #将坐标保存到vtk\n",
    "    save_path=\"../graph_file/result_low_matrix_vtk/\"\n",
    "    save_vtk(result_vertice,save_path+key+\".vtk\")\n",
    "\n",
    "\n",
    "file=os.listdir(\"../graph_file/result_low_matrix/\")\n",
    "file=[i[:6] for i in file if i.endswith(\"txt\")]\n",
    "for key in file:\n",
    "    get_node_vtk_from_low_matrix(key)    \n",
    "    \n",
    "# get_node_vtk_from_low_matrix(\"115825\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python实现从服务器远程下载文件\n",
    "import paramiko\n",
    "import os\n",
    "from stat import S_ISDIR  as isdir\n",
    "def down_from_remote(sftp_obj, remote_dir_name, local_dir_name):\n",
    "    \"\"\"远程下载文件\"\"\"\n",
    "    remote_file = sftp_obj.stat(remote_dir_name)\n",
    "    if isdir(remote_file.st_mode):\n",
    "        # 文件夹，不能直接下载，需要继续循环\n",
    "        check_local_dir(local_dir_name)\n",
    "        print('开始下载文件夹：' + remote_dir_name)\n",
    "        for remote_file_name in sftp.listdir(remote_dir_name):\n",
    "            sub_remote = os.path.join(remote_dir_name, remote_file_name)\n",
    "            sub_remote = sub_remote.replace('\\\\', '/')\n",
    "            sub_local = os.path.join(local_dir_name, remote_file_name)\n",
    "            sub_local = sub_local.replace('\\\\', '/')\n",
    "            down_from_remote(sftp_obj, sub_remote, sub_local)\n",
    "    else:\n",
    "        # 文件，直接下载\n",
    "        if remote_dir_name.endswith('input_surface.vtk'):\n",
    "\n",
    "            print('开始下载文件：' + remote_dir_name)\n",
    "            sftp_obj.get(remote_dir_name, local_dir_name)\n",
    "        # print('开始下载文件：' + remote_dir_name)\n",
    "        # sftp.get(remote_dir_name, local_dir_name)\n",
    " \n",
    "def download_vtk_files(sftp_obj,remote_dir_name,local_dir_name):\n",
    "    remote_file = sftp_obj.stat(remote_dir_name)\n",
    "    \n",
    "    dirs=sftp.listdir(remote_dir_name)\n",
    "    for dir in dirs:\n",
    "        try:\n",
    "            file=sftp.listdir(os.path.join(remote_dir_name,dir))\n",
    "            for f in file:\n",
    "                \n",
    "                if f.endswith('input_surface.vtk'):\n",
    "                    try:\n",
    "                        sftp_obj.get(remote_dir_name+\"/\"+dir+\"/\"+f, local_dir_name+dir+\"_\"+f)\n",
    "                        print('开始下载文件：' + remote_dir_name+dir+f)\n",
    "                    except:\n",
    "                        pass\n",
    "        except:\n",
    "            pass\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_local_dir(local_dir_name):\n",
    "    \"\"\"本地文件夹是否存在，不存在则创建\"\"\"\n",
    "    if not os.path.exists(local_dir_name):\n",
    "        os.makedirs(local_dir_name)\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"程序主入口\"\"\"\n",
    "    # 服务器连接信息\n",
    "    host_name = '10.69.47.36'\n",
    "    user_name = 'haiyang'\n",
    "    password = '123456'\n",
    "    port = 2222\n",
    "    # 远程文件路径（需要绝对路径）\n",
    "    remote_dir = '/disk1/wjunx/data/HCP900/'\n",
    "    # 本地文件存放路径（绝对路径或者相对路径都可以）\n",
    "    local_dir = '../matfile/surface_vtk_file/'\n",
    "\n",
    " \n",
    "    # 连接远程服务器\n",
    "    t = paramiko.Transport((host_name, port))\n",
    "    t.connect(username=user_name, password=password)\n",
    "    sftp = paramiko.SFTPClient.from_transport(t)\n",
    " \n",
    "    # 远程文件开始下载\n",
    "    # down_from_remote(sftp, remote_dir, local_dir)\n",
    "    download_vtk_files(sftp,remote_dir,local_dir)\n",
    " \n",
    "    # 关闭连接\n",
    "    t.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寻找两个个体之间的相交index\n",
    "def get_node_vtk_from_low_matrix(key):\n",
    "    result_path=\"../graph_file/result_low_matrix/\"\n",
    "    oringin_graph_path=\"../graph_file/low_matrix/\"\n",
    "    index_path=\"../matfile/functional_and_structual_matrix/\"\n",
    "    surface_path=\"../matfile/surfaces/\"\n",
    "\n",
    "    # surface_data=sio.loadmat(\"../matfile/surface_data.mat\")[\"surface_data\"]\n",
    "    edge_list=load_edge_from_txt(oringin_graph_path+key+\".txt\")\n",
    "    edge_list=[(int(i[0]),int(i[1])) for i in edge_list]\n",
    "    _,_,dic2=reindex(edge_list)\n",
    "    result_nodes=[]\n",
    "    with open(result_path+key+\".txt\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            result_nodes.append(dic2[int(line.strip())])\n",
    "    index_low_matrix=[]\n",
    "    with open(index_path+key+\"all_inde.txt\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            index_low_matrix.append(int(line.strip()))\n",
    "    index_dic={}\n",
    "    for i in range(len(index_low_matrix)):\n",
    "        \n",
    "        index_dic[i]=index_low_matrix[i]\n",
    "    # vertex_data=sio.loadmat(surface_path+key+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "    # result_vertice=[]\n",
    "    result_index=[]\n",
    "    \n",
    "    # print(result_nodes)\n",
    "    for i in result_nodes[:200]:\n",
    "        #此处-1是为了匹配matlab数据中的Index\n",
    "        # index_dic[i]\n",
    "        result_index.append(index_dic[i]-1)\n",
    "    #将坐标保存到vtk\n",
    "    return result_index\n",
    "    # save_path=\"../graph_file/result_low_matrix_vtk/\"\n",
    "    # save_vtk(result_vertice,save_path+key+\".vtk\")\n",
    "\n",
    "file=os.listdir(\"../graph_file/result_low_matrix/\")\n",
    "file=[i[:6] for i in file if i.endswith(\"txt\")]\n",
    "for key in  tqdm(file[:15]):\n",
    "    for key1 in file[:15]:\n",
    "    \n",
    "        keys_oo=get_node_vtk_from_low_matrix(key)    \n",
    "        key1=get_node_vtk_from_low_matrix(key1)\n",
    "        #求两个集合交集的元素个数\n",
    "        print(len(set(keys_oo).intersection(set(key1))))\n",
    "        \n",
    "    # print(keys_oo)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6218001e1394f6dfc9651e69e6113b19d5ca4029843c0307c1418fcabe8710e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
