{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先获取数据列表\n",
    "key_files=[]\n",
    "key_files=os.listdir(\"../matfile/distance_4/\")\n",
    "key_files=[file   for file in key_files  if file.endswith(\"keys.mat\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'114621keys.mat'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file=key_files[0]\n",
    "file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从mat文件提取数据\n",
    "def load_edge(filename):\n",
    "    \"\"\"\n",
    "    Loads the edge list from a file.\n",
    "    \"\"\"\n",
    "    edge_list = sio.loadmat(filename)\n",
    "    # print(edge_list['edge_info_key\"][0])\n",
    "    edgelist=[]\n",
    "    for edge in edge_list['edge_key'][0]:\n",
    "        edgelist.append(edge[0].split(\"+\"))\n",
    "    # print(edgelist)\n",
    "    # return edge_list['edge_list']\n",
    "    return edgelist\n",
    "# load_edge('../matFile/edge_keys.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98730\n"
     ]
    }
   ],
   "source": [
    "edge_list=load_edge('../matfile/distance_4/'+file)\n",
    "edge_list\n",
    "print(len(edge_list))\n",
    "\n",
    "# edge_list=remove_and_sort1(edge_list)\n",
    "# print(len(edge_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在去重\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98730/98730 [00:00<00:00, 232150.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88495\n",
      "[[1, 1044], [1, 1199], [2, 17], [2, 18], [2, 61], [2, 312], [2, 411], [2, 412], [2, 416], [2, 511]]\n"
     ]
    }
   ],
   "source": [
    "class Edge:\n",
    "    def __init__(self,edge0,edge1) -> None:\n",
    "        self.edge0=edge0 if edge0<edge1 else edge1\n",
    "        self.edge1=edge1 if edge0<edge1 else edge0\n",
    "        \n",
    "        \n",
    "    def __eq__(self, o: object) -> bool:\n",
    "        return self.edge0==o.edge0 and self.edge1==o.edge1\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.edge0,self.edge1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_and_sort(edge_key_list):\n",
    "    removed_list=[]\n",
    "    edge_list_sort=[[int(x[0]),int(x[1])]if int(x[0])<int(x[1]) else [int(x[1]),int(x[0])] for x in edge_key_list]\n",
    "    edge_set=set()\n",
    "    print(\"正在去重\")\n",
    "    for item in tqdm(edge_list_sort):\n",
    "        if item[0]!=item[1]:\n",
    "            edge_set.add(Edge(item[0],item[1]))\n",
    "    for item in edge_set:\n",
    "        removed_list.append([item.edge0,item.edge1])\n",
    "    list_sort=[value for index, value in sorted(enumerate(removed_list), key=lambda d:d[1])]\n",
    "    return list_sort\n",
    "    \n",
    "\n",
    "\n",
    "edge_new=remove_and_sort(edge_list)\n",
    "print(len(edge_new))\n",
    "print(edge_new[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理索引压缩\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88495/88495 [00:00<00:00, 837103.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 998],\n",
       " [0, 1151],\n",
       " [1, 16],\n",
       " [1, 17],\n",
       " [1, 52],\n",
       " [1, 291],\n",
       " [1, 388],\n",
       " [1, 389],\n",
       " [1, 393],\n",
       " [1, 488]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reindex(edge_list):\n",
    "    print(\"正在处理索引压缩\")\n",
    "    node_unique=[]\n",
    "    for it in tqdm(edge_list) :\n",
    "        node_unique.append(it[0])\n",
    "        node_unique.append(it[1])\n",
    "    node_unique=list(set(node_unique))\n",
    "    node_unique.sort()\n",
    "\n",
    "\n",
    "    anti_dict={}\n",
    "\n",
    "    node_unique_dict={}\n",
    "    for i,ele in enumerate(node_unique):\n",
    "        node_unique_dict[ele]=i\n",
    "        anti_dict[i]=ele\n",
    "\n",
    "    edge_list_new=[[node_unique_dict[x[0]],node_unique_dict[x[1]]] for x in edge_list]\n",
    "    edge_list_unique=[]\n",
    "    \n",
    "    return edge_list_new,node_unique_dict,anti_dict\n",
    "edgeeee,dic,dic1=reindex(edge_new)\n",
    "print(len(edgeeee))\n",
    "edgeeee[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_new=edge_list.copy()\n",
    "list(set(edge_list[0]))\n",
    "set((2,3))\n",
    "set([1,3])\n",
    "class Edge:\n",
    "    def __init__(self,edge0,edge1) -> None:\n",
    "        self.edge0=edge0 if edge0<edge1 else edge1\n",
    "        self.edge1=edge1 if edge0<edge1 else edge0\n",
    "        \n",
    "        \n",
    "    def __eq__(self, o: object) -> bool:\n",
    "        return self.edge0==o.edge0 and self.edge1==o.edge1\n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.edge0,self.edge1))\n",
    "sss=set()\n",
    "sss.add(Edge(1,2))\n",
    "print(sss)\n",
    "\n",
    "\n",
    "for edge in edge_list:\n",
    "    sss.add(Edge(edge[0],edge[1]))\n",
    "for i in sss:\n",
    "    print(i.edge0,i.edge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理索引压缩\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88495/88495 [00:05<00:00, 16593.34it/s]\n",
      "100%|██████████| 88495/88495 [01:49<00:00, 806.75it/s] \n"
     ]
    }
   ],
   "source": [
    "edge_list_new,node_unique_dict,anti_dic=reindex(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理索引压缩\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88495/88495 [00:04<00:00, 17934.22it/s]\n",
      "100%|██████████| 88495/88495 [02:04<00:00, 708.36it/s] \n"
     ]
    }
   ],
   "source": [
    "edge_new_reindex,node_unique_dict,anti_dic=reindex(edge_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_txt():\n",
    "    with open(f\"../graph_file/{file[:6]}1.txt\",\"w\") as f:\n",
    "        for edge in edgeeee:\n",
    "            f.write(str(edge[0])+\" \"+str(edge[1])+\"\\n\")\n",
    "\n",
    "save_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    " \n",
    " \n",
    "def count_time(fun):\n",
    "    def warpper(*args):\n",
    "        s_time = time.time()\n",
    "        fun(*args)\n",
    "        e_time = time.time()\n",
    "        t_time = e_time - s_time\n",
    "        print('%s耗时：%s' % (fun.__name__, t_time))\n",
    " \n",
    "    return warpper\n",
    " \n",
    " \n",
    " \n",
    "@count_time\n",
    "def in_list(times,size):\n",
    "    larget_list = list(range(size))\n",
    "    count = 0\n",
    "    for i in range(times):\n",
    "        num = random.randint(0, size * 2)\n",
    "        if num in larget_list:\n",
    "            count += 1\n",
    "    print (count)\n",
    " \n",
    " \n",
    "@count_time\n",
    "def in_set(times,size):\n",
    "    larget_set = set(range(size))\n",
    "    count = 0\n",
    "    for i in range(times):\n",
    "        num = random.randint(0, size * 2)\n",
    "        if num in larget_set:\n",
    "            count += 1\n",
    "    print (count)\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    times = 10000\n",
    "    size = 10000\n",
    "    in_set(times,size)\n",
    "    in_list(times,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['114621keys.mat',\n",
       " '114823keys.mat',\n",
       " '115017keys.mat',\n",
       " '115219keys.mat',\n",
       " '115320keys.mat',\n",
       " '115825keys.mat',\n",
       " '116221keys.mat',\n",
       " '116524keys.mat',\n",
       " '116726keys.mat',\n",
       " '117122keys.mat',\n",
       " '117324keys.mat',\n",
       " '117930keys.mat',\n",
       " '118023keys.mat',\n",
       " '118124keys.mat',\n",
       " '118225keys.mat',\n",
       " '118528keys.mat',\n",
       " '118730keys.mat',\n",
       " '118932keys.mat',\n",
       " '119126keys.mat',\n",
       " '119732keys.mat',\n",
       " '119833keys.mat',\n",
       " '120111keys.mat',\n",
       " '120212keys.mat',\n",
       " '120515keys.mat',\n",
       " '120717keys.mat',\n",
       " '121416keys.mat',\n",
       " '121618keys.mat',\n",
       " '121921keys.mat',\n",
       " '122317keys.mat',\n",
       " '122620keys.mat',\n",
       " '122822keys.mat',\n",
       " '123117keys.mat',\n",
       " '123420keys.mat',\n",
       " '123521keys.mat',\n",
       " '123824keys.mat',\n",
       " '123925keys.mat',\n",
       " '124220keys.mat',\n",
       " '124422keys.mat',\n",
       " '124624keys.mat',\n",
       " '124826keys.mat',\n",
       " '125525keys.mat',\n",
       " '126325keys.mat',\n",
       " '126628keys.mat',\n",
       " '127327keys.mat',\n",
       " '127630keys.mat',\n",
       " '127933keys.mat',\n",
       " '128026keys.mat',\n",
       " '128127keys.mat',\n",
       " '128632keys.mat',\n",
       " '128935keys.mat',\n",
       " '129028keys.mat',\n",
       " '129129keys.mat',\n",
       " '129331keys.mat',\n",
       " '129634keys.mat',\n",
       " '129937keys.mat',\n",
       " '130013keys.mat',\n",
       " '130316keys.mat',\n",
       " '130417keys.mat',\n",
       " '130619keys.mat',\n",
       " '130821keys.mat',\n",
       " '130922keys.mat',\n",
       " '131217keys.mat',\n",
       " '131419keys.mat',\n",
       " '131722keys.mat',\n",
       " '131823keys.mat',\n",
       " '131924keys.mat',\n",
       " '132017keys.mat',\n",
       " '132118keys.mat',\n",
       " '133019keys.mat',\n",
       " '133625keys.mat',\n",
       " '133827keys.mat',\n",
       " '133928keys.mat',\n",
       " '134021keys.mat',\n",
       " '134223keys.mat',\n",
       " '134324keys.mat',\n",
       " '134425keys.mat',\n",
       " '134728keys.mat',\n",
       " '134829keys.mat',\n",
       " '135225keys.mat',\n",
       " '135528keys.mat',\n",
       " '135730keys.mat',\n",
       " '135932keys.mat',\n",
       " '136227keys.mat',\n",
       " '136732keys.mat',\n",
       " '136833keys.mat',\n",
       " '137027keys.mat',\n",
       " '137128keys.mat',\n",
       " '137229keys.mat',\n",
       " '137633keys.mat',\n",
       " '137936keys.mat',\n",
       " '138231keys.mat',\n",
       " '138534keys.mat',\n",
       " '138837keys.mat',\n",
       " '139233keys.mat',\n",
       " '139637keys.mat',\n",
       " '139839keys.mat',\n",
       " '140117keys.mat',\n",
       " '140319keys.mat',\n",
       " '140420keys.mat',\n",
       " '140824keys.mat']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "import os\n",
    "#导入数据->去重->压缩索引->保存\n",
    "#首先获取数据列表\n",
    "key_files=[]\n",
    "key_files=os.listdir('../matfile/distance_4/')\n",
    "key_files=[file   for file in key_files  if file.endswith('keys.mat')]\n",
    "key_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:23<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "path=\"../matfile/distance_3/\"\n",
    "savepath=\"../graph_file/distance_3/\"\n",
    "# edge_list=load_edge(path+file)\n",
    "for file in tqdm(key_files):\n",
    "    edge_ori=load_edge(path+file)\n",
    "    edge_removed=remove_and_sort(edge_ori)\n",
    "    edge_reindexd,node_dic,node_anti_dic=reindex(edge_removed)\n",
    "    save_txt_for_edges(edge_reindexd,savepath+file[:6]+\".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_reindexd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_verticve_from_result_and_surface(result,surface):\n",
    "    result=np.array(result)\n",
    "    surface=np.array(surface)\n",
    "    result=result[:,0:3]\n",
    "    surface=surface[:,0:3]\n",
    "    result=np.concatenate((result,surface),axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'INDEX'])\n",
      "[62223     1     2 ... 64927 64931 64953]\n",
      "6441\n"
     ]
    }
   ],
   "source": [
    "#根据结果的索引->antidic获取处理后的索引->index索引获取原始索引->根据最终索引得到原始surface上的坐标，写入可视化文件中\n",
    "#测试读取index文件\n",
    "import scipy.io as sio\n",
    "\n",
    "index_file=\"../matfile/surfaces/114823INDEx.mat\"\n",
    "data=sio.loadmat(index_file)\n",
    "print(data.keys())\n",
    "print(data[\"INDEX\"][0][0][0])\n",
    "index_surface=data[\"INDEX\"][0][0][0][1:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'surface'])\n",
      "(64984, 3)\n"
     ]
    }
   ],
   "source": [
    "#测试读取surface文件\n",
    "surface_file=\"../matfile/surfaces/114823surface.mat\"\n",
    "data=sio.loadmat(surface_file)\n",
    "print(data.keys())\n",
    "vetice_data=data[\"surface\"][0][0][0].T\n",
    "print(vetice_data.shape)\n",
    "# print(data[\"surface\"][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100206surface.mat', '106319surface.mat', '110007surface.mat', '113215surface.mat', '114621surface.mat', '114823surface.mat', '115017surface.mat', '115219surface.mat', '115320surface.mat', '115825surface.mat', '116221surface.mat', '116524surface.mat', '116726surface.mat', '117122surface.mat', '117324surface.mat', '117930surface.mat', '118023surface.mat', '118124surface.mat', '118225surface.mat', '118528surface.mat', '118730surface.mat', '118932surface.mat', '119126surface.mat', '119732surface.mat', '119833surface.mat', '120111surface.mat', '120212surface.mat', '120515surface.mat', '120717surface.mat', '121416surface.mat', '121618surface.mat', '121921surface.mat', '122317surface.mat', '122620surface.mat', '122822surface.mat', '123117surface.mat', '123420surface.mat', '123521surface.mat', '123824surface.mat', '123925surface.mat', '124220surface.mat', '124422surface.mat', '124624surface.mat', '124826surface.mat', '125525surface.mat', '126325surface.mat', '126628surface.mat', '127327surface.mat', '127630surface.mat', '127933surface.mat', '128026surface.mat', '128127surface.mat', '128632surface.mat', '128935surface.mat', '129028surface.mat', '129129surface.mat', '129331surface.mat', '129634surface.mat', '129937surface.mat', '130013surface.mat', '130316surface.mat', '130417surface.mat', '130619surface.mat', '130821surface.mat', '130922surface.mat', '131217surface.mat', '131419surface.mat', '131722surface.mat', '131823surface.mat', '131924surface.mat', '132017surface.mat', '132118surface.mat', '133019surface.mat', '133625surface.mat', '133827surface.mat', '133928surface.mat', '134021surface.mat', '134223surface.mat', '134324surface.mat', '134425surface.mat', '134728surface.mat', '134829surface.mat', '135225surface.mat', '135528surface.mat', '135730surface.mat', '135932surface.mat', '136227surface.mat', '136732surface.mat', '136833surface.mat', '137027surface.mat', '137128surface.mat', '137229surface.mat', '137633surface.mat', '137936surface.mat', '138231surface.mat', '138534surface.mat', '138837surface.mat', '139233surface.mat', '139637surface.mat', '139839surface.mat', '140117surface.mat', '140319surface.mat', '140420surface.mat', '140824surface.mat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['100206',\n",
       " '106319',\n",
       " '110007',\n",
       " '113215',\n",
       " '114621',\n",
       " '114823',\n",
       " '115017',\n",
       " '115219',\n",
       " '115320',\n",
       " '115825',\n",
       " '116221',\n",
       " '116524',\n",
       " '116726',\n",
       " '117122',\n",
       " '117324',\n",
       " '117930',\n",
       " '118023',\n",
       " '118124',\n",
       " '118225',\n",
       " '118528',\n",
       " '118730',\n",
       " '118932',\n",
       " '119126',\n",
       " '119732',\n",
       " '119833',\n",
       " '120111',\n",
       " '120212',\n",
       " '120515',\n",
       " '120717',\n",
       " '121416',\n",
       " '121618',\n",
       " '121921',\n",
       " '122317',\n",
       " '122620',\n",
       " '122822',\n",
       " '123117',\n",
       " '123420',\n",
       " '123521',\n",
       " '123824',\n",
       " '123925',\n",
       " '124220',\n",
       " '124422',\n",
       " '124624',\n",
       " '124826',\n",
       " '125525',\n",
       " '126325',\n",
       " '126628',\n",
       " '127327',\n",
       " '127630',\n",
       " '127933',\n",
       " '128026',\n",
       " '128127',\n",
       " '128632',\n",
       " '128935',\n",
       " '129028',\n",
       " '129129',\n",
       " '129331',\n",
       " '129634',\n",
       " '129937',\n",
       " '130013',\n",
       " '130316',\n",
       " '130417',\n",
       " '130619',\n",
       " '130821',\n",
       " '130922',\n",
       " '131217',\n",
       " '131419',\n",
       " '131722',\n",
       " '131823',\n",
       " '131924',\n",
       " '132017',\n",
       " '132118',\n",
       " '133019',\n",
       " '133625',\n",
       " '133827',\n",
       " '133928',\n",
       " '134021',\n",
       " '134223',\n",
       " '134324',\n",
       " '134425',\n",
       " '134728',\n",
       " '134829',\n",
       " '135225',\n",
       " '135528',\n",
       " '135730',\n",
       " '135932',\n",
       " '136227',\n",
       " '136732',\n",
       " '136833',\n",
       " '137027',\n",
       " '137128',\n",
       " '137229',\n",
       " '137633',\n",
       " '137936',\n",
       " '138231',\n",
       " '138534',\n",
       " '138837',\n",
       " '139233',\n",
       " '139637',\n",
       " '139839',\n",
       " '140117',\n",
       " '140319',\n",
       " '140420',\n",
       " '140824']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "files=os.listdir(\"../matfile/surfaces/\")\n",
    "files=[file for file in files if file.endswith(\"surface.mat\")]\n",
    "print(files)\n",
    "keys=[file[:6] for file in files]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "person=[\"114823\", \"115017\", \"115219\", \"115320\",\"115825\", \"116221\", \"116524\", \"116726\", \"117122\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100206不存在\n",
      "[Errno 2] No such file or directory: '../matfile/distance_4/100206keys.mat'\n",
      "106319不存在\n",
      "[Errno 2] No such file or directory: '../matfile/distance_4/106319keys.mat'\n",
      "110007不存在\n",
      "[Errno 2] No such file or directory: '../matfile/distance_4/110007keys.mat'\n",
      "113215不存在\n",
      "[Errno 2] No such file or directory: '../matfile/distance_4/113215keys.mat'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [01:51<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import scipy.io as sio\n",
    "import os\n",
    "# '115320'号个体暂时有点问题\n",
    "# keys=[\n",
    "#  '114823',\n",
    "#  '115017',\n",
    "#  '115219',\n",
    "\n",
    "#  '115825',\n",
    "#  '116221',\n",
    "#  '116524',\n",
    "#  '116726',\n",
    "#  '117122']\n",
    "from tqdm import tqdm\n",
    "def get_node_verticve_from_result_and_surface(INDEX_mat_file,node_anti_dic,result_node_file,surface_mat_file):\n",
    "        nodes=[]\n",
    "        with open(result_node_file,\"r\") as f:\n",
    "            for line in f.readlines()[:200]:\n",
    "                nodes.append(int(line))\n",
    "        nodes_for_origin=[node_anti_dic[node] for node in nodes]\n",
    "        INDEX_dic=[]\n",
    "        data=sio.loadmat(INDEX_mat_file)\n",
    "        INDEX_dic=data[\"INDEX\"][0][0][0][1:]\n",
    "        \n",
    "        surface_data=sio.loadmat(surface_mat_file)\n",
    "        vetice_data=surface_data[\"surface\"][0][0][0].T\n",
    "        vertice=[]\n",
    "        for node in nodes_for_origin:\n",
    "            \n",
    "            vertice.append(vetice_data[int(INDEX_dic[int(node)-1])-1])\n",
    "        return vertice\n",
    "def save_vtk(result,filename):\n",
    "        with open(filename,\"w\") as f:\n",
    "            f.write(\"# vtk DataFile Version 3.0\\nmesh surface\\nASCII\\nDATASET POLYDATA\\n\")\n",
    "            f.write(\"POINTS \"+str(len(result))+\" float\\n\")\n",
    "            for ve in result:\n",
    "            \n",
    "                f.write(str(ve[0])+\" \"+str(ve[1])+\" \"+str(ve[2])+\"\\n\")\n",
    "distance_type=\"distance_4\"\n",
    "for key in tqdm(keys):\n",
    "    try:\n",
    "    \n",
    "\n",
    "        edge_list=load_edge(f\"../matfile/{distance_type}/{key}keys.mat\")\n",
    "        edge_list_new,node_unique_dict,anti_dic=reindex(edge_list)\n",
    "\n",
    "        vetice=get_node_verticve_from_result_and_surface(f\"../matfile/surfaces/{key}INDEX.mat\",anti_dic,f\"../graph_file/{distance_type}_result/{key}.txt\",f\"../matfile/surfaces/{key}surface.mat\")\n",
    "        \n",
    "        save_vtk(vetice,f\"./result_4_distance_vertice/graph_{key}.vtk\")\n",
    "    except Exception as e:\n",
    "        print(key+\"不存在\")\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=\"115320\"\n",
    "distance_type=\"distance_3\"\n",
    "edge_list=load_edge(f\"../matfile/{distance_type}/{key}keys.mat\")\n",
    "edge_list_new,node_unique_dict,anti_dic=reindex(edge_list)\n",
    "lis=[int(x)for x  in anti_dic.values()]\n",
    "lis.sort()\n",
    "print(lis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vtk(result,filename):\n",
    "    with open(filename,\"w\") as f:\n",
    "        f.write(\"# vtk DataFile Version 3.0\\nmesh surface\\nASCII\\nDATASET POLYDATA\\n\")\n",
    "        f.write(\"POINTS \"+str(len(result))+\" float\\n\")\n",
    "        for ve in result:\n",
    "           \n",
    "            f.write(str(ve[0])+\" \"+str(ve[1])+\" \"+str(ve[2])+\"\\n\")\n",
    "save_vtk(vetice,f\"graph_{key}.vtk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vetice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(node_unique_dict.keys())\n",
    "list1=[key for key in anti_dic.keys()]\n",
    "list1.sort()\n",
    "print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "#准备测试一致性的脚本\n",
    "keys=[\n",
    " '114823',\n",
    " '115017',\n",
    " '115219'\n",
    " '115825',\n",
    " '116221',\n",
    " '116524',\n",
    " '116726',\n",
    " '117122']\n",
    "def get_result_INDEX(person_name,distance_type=\"distance_4\"):\n",
    "    INDEX_result=[]\n",
    "    result_file=f\"../graph_file/{distance_type}_result/{person_name}.txt\"\n",
    "    edge_list=load_edge(f\"../matfile/{distance_type}/{person_name}keys.mat\")\n",
    "    _,_,anti_dic=reindex(edge_list)\n",
    "    INDEX_file=f\"../matfile/surfaces/{person_name}INDEX.mat\"\n",
    "    INDEX_dic=[]\n",
    "    data=sio.loadmat(INDEX_file)\n",
    "    INDEX_dic=data[\"INDEX\"][0][0][0][1:]\n",
    "    result_nodes_from_finder=[]\n",
    "    with open(result_file,\"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            result_nodes_from_finder.append(int(line))\n",
    "\n",
    "    for node in result_nodes_from_finder[:200]:\n",
    "        INDEX_result.append(INDEX_dic[int(anti_dic[node])-1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return INDEX_result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#获取两个个体相关的索引\n",
    "def get_consistency_of_2_person(person1,person2,index1,index2):\n",
    "    surface_path=\"../matfile/surfaces/\"\n",
    "    surface1=sio.loadmat(surface_path+person1+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "    surface2=sio.loadmat(surface_path+person2+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "   \n",
    "    nodes_result=[]\n",
    "    count=0\n",
    "    for node in index1:\n",
    "        for node2 in index2:\n",
    "            if np.linalg.norm(surface2[int(node)-1]-surface2[int(node2)-1])<7:\n",
    "                count+=1\n",
    "                nodes_result.append(node)\n",
    "                break\n",
    "    \n",
    "    return nodes_result\n",
    "\n",
    "   \n",
    "        \n",
    "\n",
    "\n",
    "# key1=\"115017\"\n",
    "# key2=\"117122\"\n",
    "# index1=get_result_INDEX(key1)\n",
    "# index2=get_result_INDEX(key2)\n",
    "# print(get_consistency_of_2_person(key1,key2,index1,index2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "[13425, 13541, 11821, 13446, 13577, 13438, 13399, 13402, 13411, 11849, 11796, 11766, 950, 11770, 11843, 13572, 13435, 13322, 11830, 1274, 11837, 13443, 42605, 11809, 11763, 13513, 13422, 13281, 13431, 27509, 13440, 4597, 13449, 12503, 11432, 27275, 35957, 40959, 35947, 13339, 118, 16304, 11428, 3703, 16294, 24471, 13240, 60973, 5693, 11435, 13283, 40962, 16105, 12497, 11686, 13841, 13569, 15904, 61088, 53652, 11979, 23968, 21441, 41113, 41128, 42647, 23150, 46972, 12, 47085, 23988, 24539, 27103, 46968, 13510, 46909, 13674, 39241, 35944, 4982, 54058, 1722, 64625, 10409, 4186, 45541, 16141, 35941, 60846, 9829, 28063, 36083, 24228, 46843, 2540, 27865, 16226, 46742, 61330, 22728, 27951, 40513, 6144, 16194, 30903, 27327, 937, 52369, 46689, 54046, 15436, 46867, 24486, 39268, 27837, 39209, 57287, 45638, 8471, 47644, 43034, 11786, 8468, 5739, 60699, 662, 13414, 30926, 56695, 41724, 9875, 25212, 61413, 15372, 2651, 44944, 45929, 11202, 61353, 52359, 12379, 41223, 4292, 9537, 12880, 12775, 44324, 24661, 47640, 24349, 24680, 56813, 8465, 16250, 52656, 21676, 36219, 63797, 60511, 22640, 11818, 15180, 21793, 12484, 39369, 6974, 22099, 38058, 53331, 16051, 39247, 44329, 22730, 53589, 11318, 17321, 32333, 55639, 24204, 47748, 55636, 51276, 41220, 31405, 60506, 55141, 18600, 37542, 37977, 9545, 52496, 38064, 31608, 56756, 4406, 10040, 38216, 38084, 56917, 18207]\n"
     ]
    }
   ],
   "source": [
    "[11647, 11082, 15125, 12957, 25755, 62142, 40964, 25863, 22544, 53576, 23281, 12230, 60176, 22428, 23722, 21604, 12187]\n",
    "print(get_consistency_of_2_person(key1,key1,index1,index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:46<00:00,  2.43s/it]\n",
      "100%|██████████| 19/19 [00:46<00:00,  2.43s/it]\n",
      "100%|██████████| 19/19 [00:45<00:00,  2.39s/it]\n",
      "100%|██████████| 19/19 [00:45<00:00,  2.42s/it]\n",
      "100%|██████████| 19/19 [00:44<00:00,  2.34s/it]\n",
      "100%|██████████| 19/19 [00:42<00:00,  2.23s/it]\n",
      "100%|██████████| 19/19 [00:44<00:00,  2.34s/it]\n",
      "100%|██████████| 19/19 [00:45<00:00,  2.39s/it]\n",
      "100%|██████████| 19/19 [00:46<00:00,  2.47s/it]\n",
      "100%|██████████| 19/19 [00:44<00:00,  2.33s/it]\n",
      "100%|██████████| 19/19 [00:47<00:00,  2.49s/it]\n",
      "100%|██████████| 19/19 [00:43<00:00,  2.28s/it]\n",
      "100%|██████████| 19/19 [00:46<00:00,  2.46s/it]\n",
      "100%|██████████| 19/19 [00:46<00:00,  2.43s/it]\n",
      "100%|██████████| 19/19 [00:45<00:00,  2.41s/it]\n",
      "100%|██████████| 19/19 [00:45<00:00,  2.39s/it]\n",
      "100%|██████████| 19/19 [00:46<00:00,  2.43s/it]\n",
      "100%|██████████| 19/19 [00:45<00:00,  2.38s/it]\n",
      "100%|██████████| 19/19 [00:44<00:00,  2.37s/it]\n",
      "100%|██████████| 19/19 [14:22<00:00, 45.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        114823  115017  115219  115825  116221  116524  116726  117122  \\\n",
      "114823   200.0    61.0    63.0    76.0    49.0    57.0    57.0    55.0   \n",
      "115017    74.0   200.0    43.0    76.0    40.0    84.0    80.0    51.0   \n",
      "115219    78.0    52.0   200.0    65.0    71.0    64.0    48.0    46.0   \n",
      "115825    78.0    84.0    59.0   200.0    48.0    76.0    76.0    55.0   \n",
      "116221    52.0    56.0    70.0    52.0   200.0    49.0    53.0    57.0   \n",
      "116524    59.0    76.0    55.0    71.0    49.0   200.0    86.0    46.0   \n",
      "116726    59.0    82.0    38.0    74.0    40.0    83.0   200.0    60.0   \n",
      "117122    56.0    52.0    57.0    64.0    66.0    39.0    61.0   200.0   \n",
      "118023    45.0    56.0    49.0    61.0    65.0    58.0    60.0    96.0   \n",
      "118124    48.0    47.0    43.0    56.0    45.0    41.0    46.0    58.0   \n",
      "118225    64.0    51.0    76.0    68.0    68.0    44.0    50.0    65.0   \n",
      "118528    56.0    59.0    50.0    55.0    47.0    51.0    65.0    86.0   \n",
      "118730    53.0    46.0    61.0    55.0    65.0    56.0    55.0    69.0   \n",
      "118932    85.0    60.0    90.0    68.0    71.0    51.0    48.0    63.0   \n",
      "119126    41.0    52.0    48.0    75.0    54.0    71.0    75.0    82.0   \n",
      "119732    56.0    77.0    42.0    61.0    51.0    76.0    82.0    79.0   \n",
      "119833   103.0    63.0    72.0    72.0    50.0    68.0    59.0    46.0   \n",
      "120111    71.0    60.0    79.0    65.0    58.0    53.0    41.0    48.0   \n",
      "120212    58.0    47.0    60.0    38.0    64.0    50.0    47.0    62.0   \n",
      "\n",
      "        118023  118124  118225  118528  118730  118932  119126  119732  \\\n",
      "114823    57.0    72.0    52.0    63.0    55.0    64.0    55.0    47.0   \n",
      "115017    74.0    72.0    38.0    73.0    50.0    50.0    62.0    72.0   \n",
      "115219    54.0    59.0    62.0    54.0    59.0    86.0    47.0    54.0   \n",
      "115825    71.0    77.0    39.0    55.0    44.0    54.0    64.0    71.0   \n",
      "116221    60.0    54.0    46.0    55.0    74.0    66.0    56.0    55.0   \n",
      "116524    63.0    55.0    32.0    52.0    49.0    43.0    58.0    58.0   \n",
      "116726    48.0    63.0    37.0    65.0    47.0    45.0    56.0    71.0   \n",
      "117122    92.0    90.0    64.0    89.0    66.0    60.0    91.0    79.0   \n",
      "118023   200.0    96.0    54.0    93.0    49.0    47.0    88.0    74.0   \n",
      "118124    71.0   200.0    40.0    68.0    41.0    38.0    81.0    49.0   \n",
      "118225    58.0    65.0   200.0    65.0    69.0    88.0    51.0    65.0   \n",
      "118528    95.0    80.0    49.0   200.0    54.0    52.0    93.0    77.0   \n",
      "118730    63.0    52.0    53.0    56.0   200.0    62.0    50.0    58.0   \n",
      "118932    49.0    62.0    67.0    59.0    65.0   200.0    46.0    70.0   \n",
      "119126    91.0   106.0    49.0    94.0    51.0    43.0   200.0    80.0   \n",
      "119732    74.0    75.0    53.0    82.0    42.0    61.0    85.0   200.0   \n",
      "119833    57.0    57.0    42.0    57.0    49.0    62.0    52.0    52.0   \n",
      "120111    51.0    66.0    56.0    50.0    56.0    72.0    49.0    54.0   \n",
      "120212    55.0    72.0    47.0    65.0    56.0    50.0    64.0    52.0   \n",
      "\n",
      "        119833  120111  120212  \n",
      "114823    91.0    65.0    52.0  \n",
      "115017    64.0    58.0    60.0  \n",
      "115219    71.0    69.0    63.0  \n",
      "115825    76.0    59.0    42.0  \n",
      "116221    53.0    55.0    57.0  \n",
      "116524    62.0    39.0    57.0  \n",
      "116726    52.0    36.0    59.0  \n",
      "117122    52.0    41.0    71.0  \n",
      "118023    56.0    45.0    69.0  \n",
      "118124    49.0    43.0    57.0  \n",
      "118225    59.0    67.0    73.0  \n",
      "118528    43.0    48.0    67.0  \n",
      "118730    50.0    57.0    56.0  \n",
      "118932    66.0    64.0    61.0  \n",
      "119126    53.0    49.0    63.0  \n",
      "119732    55.0    50.0    48.0  \n",
      "119833   200.0    64.0    63.0  \n",
      "120111    70.0   200.0    57.0  \n",
      "120212    57.0    50.0   200.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "keys=[\n",
    " '114823',\n",
    " '115017',\n",
    " '115219',\n",
    " '115825',\n",
    " '116221',\n",
    " '116524',\n",
    " '116726',\n",
    " '117122',\n",
    "  '118023',\n",
    " '118124',\n",
    " '118225',\n",
    " '118528',\n",
    " '118730',\n",
    " '118932',\n",
    " '119126',\n",
    " '119732',\n",
    " '119833',\n",
    " '120111',\n",
    " '120212',]\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm,trange\n",
    "data_result=pd.DataFrame()\n",
    " \n",
    "for i in trange(len(keys)):\n",
    "    for j in trange(len(keys)):\n",
    "        key1=keys[i]\n",
    "        key2=keys[j]     \n",
    "        index1=get_result_INDEX(key1)\n",
    "\n",
    "        index2=get_result_INDEX(key2)\n",
    "        count=get_consistency_of_2_person(key1,key2,index1,index2)\n",
    "        data_result.loc[i,j]=len(count)\n",
    "data_result.columns=keys\n",
    "data_result.index=keys\n",
    "data_result.to_csv(\"result_7.csv\")\n",
    "print(data_result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=[\n",
    " '114823',\n",
    " '115017',\n",
    " '115219',\n",
    " '115825',\n",
    " '116221',\n",
    " '116524',\n",
    " '116726',\n",
    " '117122']\n",
    "import pandas as pd   \n",
    "\n",
    "data=pd.read_csv(\"result.csv\",index_col=0)\n",
    "# keys.append(\"index\")\n",
    "data.columns=keys\n",
    "data.index=keys\n",
    "data\n",
    "data.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#以某一个个体为模板，找到与其他个体最相似的部分\n",
    "\n",
    "def get_consistency_of_2_person_return_index(person1,person2,index1,index2):\n",
    "    #分别返回两个个体间的相似部分索引\n",
    "    surface_path=\"../matfile/surfaces/\"\n",
    "    surface1=sio.loadmat(surface_path+person1+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "    surface2=sio.loadmat(surface_path+person2+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "   \n",
    "    nodes_result=[]\n",
    "    result_index1=[]\n",
    "    result_index2=[]\n",
    "    count=0\n",
    "    for node in index1:\n",
    "        for node2 in index2:\n",
    "            if np.linalg.norm(surface2[int(node)-1]-surface2[int(node2)-1])<7:\n",
    "                count+=1\n",
    "                result_index1.append(node)\n",
    "                result_index2.append(node2)\n",
    "                nodes_result.append(node)\n",
    "                break\n",
    "    \n",
    "    return result_index1,result_index2\n",
    "def save_vertice_from_INDEX(person,indexs,filename):\n",
    "    surf_path=\"../matfile/surfaces/\"\n",
    "    file_path=\"./result_vertice_data/\"\n",
    "    surf_data=sio.loadmat(surf_path+person+\"surface.mat\")[\"surface\"][0][0][0].T\n",
    "    vertice=[]\n",
    "    for id in indexs:\n",
    "        vertice.append(surf_data[int(id)-1])\n",
    "    # vertice=np.array(vertice)\n",
    "    with open(file_path+filename,\"w\") as f:\n",
    "        f.write(\"# vtk DataFile Version 3.0\\nmesh surface\\nASCII\\nDATASET POLYDATA\\n\")\n",
    "        f.write(\"POINTS \"+str(len(vertice))+\" float\\n\")\n",
    "        for line in vertice:\n",
    "            f.write(str(line[0])+\" \"+str(line[1])+\" \"+str(line[2])+\"\\n\")\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm,trange\n",
    "# keys=[\n",
    "#  '114823',\n",
    "#  '115017',\n",
    "#  '115219',\n",
    "#  '115825',\n",
    "#  '116221',\n",
    "#  '116524',\n",
    "#  '116726',\n",
    "#  '117122']\n",
    "# keys=[\n",
    "    \n",
    "# ]\n",
    "for key in tqdm(keys[1:]):\n",
    "    index1,index2=get_consistency_of_2_person_return_index(\"114823\",key,get_result_INDEX(\"114823\"),get_result_INDEX(key))\n",
    "    print(index1)\n",
    "    save_vertice_from_INDEX(\"114823\",index1,\"114823_\"+key+\".vtk\")\n",
    "    save_vertice_from_INDEX(key,index2,key+\"_114823.vtk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "low_result_keys=os.list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6218001e1394f6dfc9651e69e6113b19d5ca4029843c0307c1418fcabe8710e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
